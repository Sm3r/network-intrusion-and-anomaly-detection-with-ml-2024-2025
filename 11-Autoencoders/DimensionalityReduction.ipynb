{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction with a Linear Autoencoder\n",
    "In this notebook, we will show how to use a Linear Autoencoder to visualise the network flow samples in 1, 2 and 3 dimensional spaces. To do so, we reduce the dimension of the data points from 21 features (see the flow representation below) to 1, 2 and 3 respectively. \n",
    "We do the same using PCA and we compare the results.\n",
    "\n",
    "We will use a dataset of benign and various DDoS attacks from the CIC-DDoS2019 dataset (https://www.unb.ca/cic/datasets/ddos-2019.html).\n",
    "The network traffic has been previously pre-processed in a way that packets are grouped in bi-directional traffic flows using the 5-tuple (source IP, destination IP, source Port, destination Port, protocol). Each flow is represented with 21 packet-header features computed from max 1000 packets:\n",
    "\n",
    "| Feature nr.         | Feature Name |\n",
    "|---------------------|---------------------|\n",
    "| 00 | timestamp (mean IAT) | \n",
    "| 01 | packet_length (mean)| \n",
    "| 02 | IP_flags_df (sum) |\n",
    "| 03 | IP_flags_mf (sum) |\n",
    "| 04 | IP_flags_rb (sum) | \n",
    "| 05 | IP_frag_off (sum) |\n",
    "| 06 | protocols (mean) |\n",
    "| 07 | TCP_length (mean) |\n",
    "| 08 | TCP_flags_ack (sum) |\n",
    "| 09 | TCP_flags_cwr (sum) |\n",
    "| 10 | TCP_flags_ece (sum) |\n",
    "| 11 | TCP_flags_fin (sum) |\n",
    "| 12 | TCP_flags_push (sum) |\n",
    "| 13 | TCP_flags_res (sum) |\n",
    "| 14 | TCP_flags_reset (sum) |\n",
    "| 15 | TCP_flags_syn (sum) |\n",
    "| 16 | TCP_flags_urg (sum) |\n",
    "| 17 | TCP_window_size (mean) |\n",
    "| 18 | UDP_length (mean) |\n",
    "| 19 | ICMP_type (mean) |\n",
    "| 20 | Packets (counter)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Course on Network Intrusion and Anomaly Detection with Machine Learning\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from util_functions import *\n",
    "DATASET_FOLDER = \"./DOS2019_4_ATTACKS\"\n",
    "target_names = ['dns', 'syn','tftp','webddos'] \n",
    "CLASSES = len(target_names)\n",
    "data, labels = load_dataset(DATASET_FOLDER + \"/*\" + '-train.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for the three classes\n",
    "def plot_components(data_1d,data_2d,data_3d):\n",
    "    colors = ['blue', 'orange','yellow','red','black']\n",
    "\n",
    "    # Plotting the original data in 3D with colored labels\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "    ax = fig.add_subplot(131, projection='3d')\n",
    "    for label, color in zip(range(CLASSES), colors):\n",
    "        indices = labels == label\n",
    "        ax.scatter(data_3d[indices, 0], data_3d[indices, 1], data_3d[indices, 2], label=f'{target_names[label]}', marker='o', color=color)\n",
    "    ax.set_title('3D Projection with Labels')\n",
    "    ax.set_xlabel('PCA1')\n",
    "    ax.set_ylabel('PCA2')\n",
    "    ax.set_zlabel('PCA3')\n",
    "    ax.legend()\n",
    "    # Set azimuth and elevation angles for rotation\n",
    "    ax.view_init(elev=30, azim=0)\n",
    "\n",
    "    # Plotting the reduced data in 2D with colored labels\n",
    "    ax = fig.add_subplot(132)\n",
    "    for label, color in zip(range(CLASSES), colors):\n",
    "        indices = labels == label\n",
    "        ax.scatter(data_2d[indices, 0], data_2d[indices, 1], label=f'{target_names[label]}', marker='o', color=color)\n",
    "    ax.set_title('2D Projection with Labels')\n",
    "    ax.set_xlabel('PCA1')\n",
    "    ax.set_ylabel('PCA2')\n",
    "    ax.legend()\n",
    "\n",
    "    # Plotting the data in 1D along the first principal component\n",
    "    ax = fig.add_subplot(133)\n",
    "    for label, color in zip(range(CLASSES), colors):\n",
    "        indices = labels == label\n",
    "        ax.scatter(data_1d[indices], np.zeros_like(data_1d[indices]) + label, label=f'{target_names[label]}', marker='o', color=color)\n",
    "\n",
    "    ax.set_title('1D Projection with Labels')\n",
    "    ax.set_xlabel('PCA1')\n",
    "    ax.set_yticks([], [])\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing PCA to reduce to 3 dimensions\n",
    "pca_3d = PCA(n_components=3)\n",
    "pca_data_3d = pca_3d.fit_transform(data)\n",
    "\n",
    "# Further reducing to 2 dimensions\n",
    "pca_2d = PCA(n_components=2)\n",
    "pca_data_2d = pca_2d.fit_transform(data)\n",
    "\n",
    "# Performing PCA to reduce to 1 dimension\n",
    "pca_1d = PCA(n_components=1)\n",
    "pca_data_1d = pca_1d.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction with Linear Autoencoder\n",
    "\n",
    "| <img src=\"./autoencoder_reduction.png\" width=\"80%\">  |\n",
    "|--|\n",
    "| Reduction to 1D, 2D and 3D data representations.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# 1D\n",
    "input_layer = Input(shape=(data.shape[1],))\n",
    "encoded_layer = Dense(1, activation='linear')(input_layer)\n",
    "decoded_layer = Dense(data.shape[1], activation='linear')(encoded_layer)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded_layer)\n",
    "print(autoencoder.summary())\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(data, data, epochs=100, batch_size=32, shuffle=True)\n",
    "# Extract the encoder model for dimensionality reduction\n",
    "encoder = Model(input_layer, encoded_layer)\n",
    "encoded_data_1d = encoder.predict(data)\n",
    "\n",
    "# 2D\n",
    "input_layer = Input(shape=(data.shape[1],))\n",
    "encoded_layer = Dense(2, activation='linear')(input_layer)\n",
    "decoded_layer = Dense(data.shape[1], activation='linear')(encoded_layer)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded_layer)\n",
    "print(autoencoder.summary())\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(data, data, epochs=100, batch_size=32, shuffle=True)\n",
    "# Extract the encoder model for dimensionality reduction\n",
    "encoder = Model(input_layer, encoded_layer)\n",
    "encoded_data_2d = encoder.predict(data)\n",
    "\n",
    "# 3D\n",
    "input_layer = Input(shape=(data.shape[1],))\n",
    "encoded_layer = Dense(3, activation='linear')(input_layer)\n",
    "decoded_layer = Dense(data.shape[1], activation='linear')(encoded_layer)\n",
    "\n",
    "autoencoder = Model(input_layer, decoded_layer)\n",
    "print(autoencoder.summary())\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(data, data, epochs=100, batch_size=32, shuffle=True)\n",
    "# Extract the encoder model for dimensionality reduction\n",
    "encoder = Model(input_layer, encoded_layer)\n",
    "encoded_data_3d = encoder.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_components(pca_data_1d,pca_data_2d,pca_data_3d)\n",
    "plot_components(encoded_data_1d,encoded_data_2d,encoded_data_3d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
