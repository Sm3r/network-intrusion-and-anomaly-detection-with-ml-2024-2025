{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression \n",
    "In this lab we train a Linear regressor with synthetic data for a regression problem (prediction of a real number). Given the \"Time\" feature, and a training set where the independent variable is the time, and the dependent variable is the average packet size. We want to predict the packet size to spot anomalies in the network traffic.\n",
    "In this lab we focus on the **problem of overfitting the training data with Polynomial Regression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Course on Network Intrusion and Anomaly Detection with Machine Learning\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUTPUT_FILE = \"./reg_tree\"\n",
    "\n",
    "# Generate some sample data (a sin function with some random noise)\n",
    "np.random.seed(0)\n",
    "m = 40\n",
    "X = 6 * np.random.rand(m, 1) - 3 \n",
    "y = 0.5 * X  + 80 + 0.3*np.random.randn(m, 1)\n",
    "\n",
    "# Fit a linear regressor\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resulting curve: \" + str(lr.intercept_[0]) + \" + \" + str(lr.coef_[0][0]) + \"*Time\") \n",
    "\n",
    "# Predictions (numbers from 0 to 5 with increment 0.01)\n",
    "X_plot = np.arange(-3, 3, 0.01)[:, np.newaxis]\n",
    "y_pred = lr.predict(X_plot)\n",
    "\n",
    "np.random.seed(1)\n",
    "X_test = 6 * np.random.rand(m, 1) - 3 \n",
    "y_test = 0.5 * X_test + 80 + 0.3*np.random.randn(m, 1)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"yellow\", label=\"training data\")\n",
    "plt.scatter(X_test, y_test, s=20, edgecolor=\"black\", c=\"red\", label=\"test data\")\n",
    "plt.plot(X_plot, y_pred, color=\"cornflowerblue\", label=\"prediction\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Linear Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Error on the training set\n",
    "y_pred = lr.predict(X)\n",
    "mse = mean_squared_error(y,y_pred)\n",
    "print(\"MSE measured on the training set: \", mse)\n",
    "\n",
    "y_pred_test = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test,y_pred_test)\n",
    "print(\"MSE measured on the test set: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with polynomial features\n",
    "You can use a linear model to fit nonlinear data. A simple way to do this is to add powers of each feature as new features, then train a linear model on this extended set of features. This technique is called Polynomial Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_poly now contains the original feature of X plus the square of this feature\n",
    "MAX_DEGREE=19\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=MAX_DEGREE, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "lr = LinearRegression() \n",
    "lr.fit(X_poly, y)\n",
    "print(lr.intercept_, lr.coef_) # print bias and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions (numbers from 0 to 5 with increment 0.01)\n",
    "X_plot = np.arange(-3, 3, 0.01)[:, np.newaxis]\n",
    "X_plot_poly = poly_features.fit_transform(X_plot)\n",
    "y_pred = lr.predict(X_plot_poly)\n",
    "\n",
    "np.random.seed(2)\n",
    "X_test = 6 * np.random.rand(m, 1) - 3 \n",
    "X_test_poly = poly_features.fit_transform(X_test)\n",
    "y_test = 0.5 * X_test + 80 + 0.3*np.random.randn(m, 1)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"yellow\", label=\"training data\")\n",
    "plt.scatter(X_test, y_test, s=20, edgecolor=\"black\", c=\"red\", label=\"test data\")\n",
    "plt.plot(X_plot, y_pred, color=\"cornflowerblue\", label=\"prediction\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.ylim([78, 82])\n",
    "plt.title(\"Polynomial Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Error on the training set\n",
    "y_pred = lr.predict(X_poly)\n",
    "mse = mean_squared_error(y,y_pred)\n",
    "print(\"MSE measured on the benign training set: \", mse)\n",
    "\n",
    "\n",
    "y_pred_test = lr.predict(X_test_poly)\n",
    "mse = mean_squared_error(y_test,y_pred_test)\n",
    "print(\"MSE measured on the test set: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the MSE trend on training and test set when varying the polynomial degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = []\n",
    "mse_test = []\n",
    "\n",
    "for degree in range(1,MAX_DEGREE+1):\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly_features.fit_transform(X)\n",
    "    X_test_poly = poly_features.fit_transform(X_test)\n",
    "\n",
    "\n",
    "    lr = LinearRegression() \n",
    "    lr.fit(X_poly, y)\n",
    "\n",
    "    y_pred = lr.predict(X_poly)\n",
    "    mse_train.append(mean_squared_error(y,y_pred))\n",
    "    y_pred_test = lr.predict(X_test_poly)\n",
    "    mse_test.append(mean_squared_error(y_test,y_pred_test))\n",
    "\n",
    "# Index for the x-axis, increasing by 1\n",
    "index = list(range(1, MAX_DEGREE+1))\n",
    "\n",
    "# Plotting the line charts for both data sets\n",
    "plt.xticks(np.arange(1, MAX_DEGREE+1, 1.0))\n",
    "plt.plot(index, mse_train, marker='o', linestyle='-', color='b', label='Training set')\n",
    "plt.plot(index, mse_test, marker='s', linestyle='--', color='r', label='The test set')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Mean Square Error (MSE)')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
