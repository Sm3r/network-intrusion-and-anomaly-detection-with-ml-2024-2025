{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71299b2",
   "metadata": {},
   "source": [
    "# Tuning and training a Convolutional Neural Network for Intrusion Detection\n",
    "In this laboratory, you will implement and tune a CNN model for binary network traffic classification. The CNN model will return a value between 0 and 1, which is the probability of the input flow of being malicious. \n",
    "You will select a range of hyperparameters to tune the CNN using Random search and you will train it on a dataset of benign traffic and DDoS attack traffic.\n",
    "\n",
    "| <img src=\"./cnn.png\" width=\"90%\">  |\n",
    "|--|\n",
    "| CNN model for binary classification|\n",
    "\n",
    "You will use a dataset of benign and various DDoS attacks from the CIC-DDoS2019 dataset (https://www.unb.ca/cic/datasets/ddos-2019.html).\n",
    "The network traffic has been previously pre-processed in a way that packets are grouped in bi-directional traffic flows using the 5-tuple (source IP, destination IP, source Port, destination Port, protocol). Each flow is represented as a **100x20 array**, where the rows are the packets of the flow in chronological order, while each column is a packet-level feature in the following order:\n",
    "\n",
    "| Feature nr.         | Feature Name |\n",
    "|---------------------|---------------------|\n",
    "| 00 | timestamp (IAT) | \n",
    "| 01 | packet_length (bytes)| \n",
    "| 02 | IP_flags_df (0/1) |\n",
    "| 03 | IP_flags_mf (0/1) |\n",
    "| 04 | IP_flags_rb (0/1) | \n",
    "| 05 | IP_frag_off (0/1) |\n",
    "| 06 | protocols (integer) |\n",
    "| 07 | TCP_length (bytes) |\n",
    "| 08 | TCP_flags_ack (0/1) |\n",
    "| 09 | TCP_flags_cwr (0/1) |\n",
    "| 10 | TCP_flags_ece (0/1) |\n",
    "| 11 | TCP_flags_fin (0/1) |\n",
    "| 12 | TCP_flags_push (0/1) |\n",
    "| 13 | TCP_flags_res (0/1) |\n",
    "| 14 | TCP_flags_reset (0/1) |\n",
    "| 15 | TCP_flags_syn (0/1) |\n",
    "| 16 | TCP_flags_urg (0/1) |\n",
    "| 17 | TCP_window_size (bytes) |\n",
    "| 18 | UDP_length (bytes) |\n",
    "| 19 | ICMP_type (code) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aec2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Course on Network Intrusion and Anomaly Detection with Machine Learning\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, GlobalMaxPooling2D, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from keras.regularizers import l1,l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "from util_functions import *\n",
    "\n",
    "# disable GPUs for test reproducibility\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "SEED=0\n",
    "\n",
    "DATASET_FOLDER = \"./DOS2019\"\n",
    "\n",
    "X_train, y_train = load_dataset(DATASET_FOLDER + \"/*\" + '-train.hdf5',channels=True)\n",
    "X_val, y_val = load_dataset(DATASET_FOLDER + \"/*\" + '-val.hdf5',channels=True)\n",
    "X_test, y_test = load_dataset(DATASET_FOLDER + \"/*\" + '-test.hdf5',channels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileModel(model,optimizer='sgd', lr=0.001):\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=lr, momentum=0.0)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "The following method defines the CNN model with configurable hyperparameters. Each hyperparameter has a default value that can be set during the tuning process. In the following cell, your task is to finalise the model by adding a **GlobalMaxPooling2D** layer, a **Flatten** layer and a final **Dense** layer with Sigmoid activation function for binary classification. Additional, you may want to add **Dropout** regularisation to your model. Take inspiration from the [CNNvsMLP](./CNNvsMLP.ipynb) and the [Hyperparameters Tuning](../09-HyperparameterTuning/hyperparameter-tuning-lab.ipynb) notebooks.\n",
    "\n",
    "You may notice that the **Convolutional** layer (Conv2D) has fixed hyperparameters' values (number of filters, kernel size, etc.). Change the code in a way that Conv2D can use the values listed in the definition of the *create_model* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f5e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the CNN model\n",
    "def create_model(optimizer='adam', filters = 100, kernel_size=(3,3), strides=(1,1), padding='same',learning_rate = 0.001,dropout_rate=0.1):\n",
    "    cnn_model = Sequential(name  = \"cnn\")\n",
    "\n",
    "    ### MODIFY THE FOLLOWING CODE\n",
    "    cnn_model.add(Conv2D(filters=100, kernel_size=(3,3), input_shape=X_train.shape[1:], data_format='channels_last', activation='relu', padding='same', strides=(1,1)))\n",
    "    \n",
    "    ### ADD YOUR CODE HERE ###\n",
    "\n",
    "    ##########################\n",
    "\n",
    "    compileModel(cnn_model, optimizer,learning_rate)\n",
    "    return cnn_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search\n",
    "The code in the following cell implements *random search* to tune the hyperparameters of the CNN model. \n",
    "\n",
    "In the cell below, add the relevant hyperparameters for the CNN to the **param_dist** dictionary. The tunable hyperparameters are those available in definition of the *create_model* above. Remember to use the *uniform* method for generating floating point values (e.g., for the **learning_rate**), use *randint* for generating the integer hyperparameters (e.g., the **number of filters**), while use lists for multi-dimensional hyperparameters (e.g., **kernel_size**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "k=2 # number of folds for cross-validation\n",
    "PATIENCE = 10\n",
    "\n",
    "# Create a KerasClassifier based on the create_model function\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=100, verbose=1)\n",
    "\n",
    "# Define the hyperparameters to tune and their possible values\n",
    "param_dist = {\n",
    "    'learning_rate' : uniform(0.0001, 0.001),\n",
    "    ### ADD YOUR CODE HERE ###\n",
    "\n",
    "    ##########################\n",
    "}\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=5, cv=k, random_state=SEED)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE, restore_best_weights=True)\n",
    "start_time = time.time()\n",
    "random_search_result = random_search.fit(X_train, y_train,epochs=100, validation_data=(X_val, y_val),callbacks= [ ])\n",
    "stop_time = time.time()\n",
    "\n",
    "# Total training time\n",
    "print(\"Total training time (sec): \", stop_time-start_time)\n",
    "\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best parameters found: \", random_search_result.best_params_)\n",
    "print(\"Best cross-validated accuracy: {:.2f}\".format(random_search_result.best_score_))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Test accuracy of the best model: {:.2f}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
